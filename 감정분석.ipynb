{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b586bd7-ae96-4099-9963-c522486631e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer and model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Correct model name for KoBERT\n",
    "model_name = 'skt/kobert-base-v1'\n",
    "\n",
    "# Use AutoTokenizer to automatically select the correct tokenizer class\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load model with the correct number of labels for classification\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "# GPU settings\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Tokenizer and model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f4937c0-976d-4608-aac5-8620af8b825c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "감정 분석 진행 중: 100%|█████████████████████████████████████████████████████████| 5000/5000 [4:38:25<00:00,  3.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# 엑셀 파일 경로\n",
    "file_path = r\"C:\\Users\\user\\Desktop\\도서관_공모전\\최종\\2_Selenium_책소개\\book_introductions.xlsx\"\n",
    "\n",
    "# 엑셀 파일 불러오기\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# KoBERT 입력 형식으로 변환하는 함수\n",
    "def preprocess(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)  # 비 문자열 입력을 문자열로 변환\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        max_length=512,  # KoBERT의 최대 입력 길이\n",
    "        add_special_tokens=True,\n",
    "        padding='max_length',\n",
    "        truncation=True,  # 긴 텍스트는 자르기\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    return encoding['input_ids'].squeeze(0), encoding['attention_mask'].squeeze(0)\n",
    "\n",
    "# 감정 예측 함수\n",
    "def predict(text):\n",
    "    try:\n",
    "        input_id, attention_mask = preprocess(text)\n",
    "        input_id = input_id.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=input_id.unsqueeze(0), attention_mask=attention_mask.unsqueeze(0))\n",
    "            logits = output.logits\n",
    "            prediction = torch.argmax(logits, dim=-1).cpu().numpy()[0]\n",
    "            probabilities = torch.softmax(logits, dim=-1).cpu().numpy()[0]\n",
    "            \n",
    "        label_dict = {0: '긍정', 1: '부정', 2: '중립'}\n",
    "        return label_dict[prediction], probabilities\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}. Error: {e}\")\n",
    "        return '오류', [0, 0, 0]  # 오류 발생 시 기본값\n",
    "\n",
    "# tqdm 적용하여 감정 분석 수행\n",
    "def analyze_sentiments(df):\n",
    "    results = []\n",
    "    for text in tqdm(df['책 소개'].fillna(''), desc=\"감정 분석 진행 중\"):  # NaN을 빈 문자열로 대체\n",
    "        sentiment, probabilities = predict(text)\n",
    "        results.append({'sentiment': sentiment, 'probabilities': probabilities})\n",
    "    return results\n",
    "\n",
    "# 감정 분석 수행\n",
    "results = analyze_sentiments(df)\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# 원본 데이터와 결과 합치기\n",
    "df = df.join(df_results)\n",
    "\n",
    "# 결과를 새로운 엑셀 파일로 저장\n",
    "output_path = r\"C:\\Users\\user\\Desktop\\도서관_공모전\\최종\\2_Selenium_책소개\\book_introductions_with_predictions.xlsx\"\n",
    "df.to_excel(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
